{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "every_emotion [[60, 34, 24], [4253, 363, 1705], [20, 12, 15], [5, 9, 3], [330, 483, 206], [31, 46, 25], [8, 86, 22]]\n",
      "every_percent [[0.5084745762711864, 0.288135593220339, 0.2033898305084746], [0.6728365764910615, 0.05742762221167537, 0.2697358012972631], [0.425531914893617, 0.2553191489361702, 0.3191489361702128], [0.29411764705882354, 0.5294117647058824, 0.17647058823529413], [0.323846908734053, 0.47399411187438667, 0.20215897939156036], [0.30392156862745096, 0.45098039215686275, 0.24509803921568626], [0.06896551724137931, 0.7413793103448276, 0.1896551724137931]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    emotions, speakers = [], []\n",
    "    dataset = 'dailydialog'\n",
    "    data = 'test'\n",
    "    file_base = '/nfs/users/gutianyun/EmoBias-ERC/model/datasets/dialogue_level_minibatch/' + dataset + '/' + dataset + '_' + data + '_'\n",
    "    file_emotions = file_base + 'emotion.tsv'\n",
    "    file_speakers = file_base + 'speakers.tsv'\n",
    "    \n",
    "    with open(file_emotions) as f:\n",
    "        for line in f:\n",
    "            content = line.strip().split('\\t')[1:]\n",
    "            emotions.append(content)\n",
    "        \n",
    "    with open(file_speakers) as f:\n",
    "        for line in f:\n",
    "            content = line.strip().split('\\t')[1:]\n",
    "            speakers.append(content)\n",
    "    \n",
    "    every_emotion = []\n",
    "    for emo_i in range(7):\n",
    "        every_emotion.append([0,0,0])\n",
    "            \n",
    "    for j, conv in enumerate(speakers):\n",
    "        unique_speakers = np.unique(conv)\n",
    "        speaker_memo = {}\n",
    "        for unique_speaker in unique_speakers:\n",
    "            speaker_memo[unique_speaker] = conv.index(unique_speaker)\n",
    "        \n",
    "        res = []\n",
    "        res.append('te_'+str(j))\n",
    "        for i, curr_speaker in enumerate(conv):\n",
    "            last_index = speaker_memo[curr_speaker]\n",
    "            speaker_memo[curr_speaker] = i\n",
    "            \n",
    "            curr_emotion = int(emotions[j][i])\n",
    "            if i == last_index:\n",
    "                every_emotion[curr_emotion][2] = every_emotion[curr_emotion][2] +1\n",
    "                res.append(2)\n",
    "            else:\n",
    "                last_emotion = int(emotions[j][last_index])\n",
    "                if last_emotion == curr_emotion:\n",
    "                    every_emotion[curr_emotion][0] = every_emotion[curr_emotion][0] +1\n",
    "                    res.append(0)\n",
    "                else:\n",
    "                    every_emotion[curr_emotion][1] = every_emotion[curr_emotion][1] +1\n",
    "                    res.append(1) \n",
    "        # print('res:', res)\n",
    "    print('every_emotion', every_emotion)\n",
    "    every_percent = []\n",
    "    for emo_i in range(7):\n",
    "        total_bias = every_emotion[emo_i][0] +every_emotion[emo_i][1] + every_emotion[emo_i][2]\n",
    "        every_percent.append([0,0,0])\n",
    "        for bias_i in range(3):\n",
    "            every_percent[emo_i][bias_i] = every_emotion[emo_i][bias_i]/total_bias\n",
    "    print('every_percent', every_percent)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "every_percent [[0.3796477495107632, 0.3639921722113503, 0.2563600782778865], [0.6804562239985041, 0.05467910064039639, 0.2648646753610994], [0.29745042492917845, 0.35410764872521244, 0.34844192634560905], [0.28160919540229884, 0.47126436781609193, 0.2471264367816092], [0.32953046177726036, 0.48257663950329843, 0.1878928987194412], [0.24, 0.46869565217391307, 0.29130434782608694], [0.08447613823368075, 0.7032364234777839, 0.21228743828853539]]\n"
     ]
    }
   ],
   "source": [
    "every_train = [[307, 305, 215], [49013, 3998, 19132], [85, 110, 108], [42, 67, 37], [3800, 5257, 2125], [239, 455, 275], [140, 1116, 344]]\n",
    "every_valid = [[21, 33, 23], [4962, 318, 1828], [0, 3, 0], [2, 6, 3], [116, 478, 90], [6, 38, 35], [6, 80, 21]]\n",
    "every_test = [[60, 34, 24], [4253, 363, 1705], [20, 12, 15], [5, 9, 3], [330, 483, 206], [31, 46, 25], [8, 86, 22]]\n",
    "\n",
    "every_percent = []\n",
    "for emo_i in range(7):\n",
    "    total_bias = every_train[emo_i][0] +every_train[emo_i][1] + every_train[emo_i][2] + every_valid[emo_i][0] +every_valid[emo_i][1] + every_valid[emo_i][2] + every_test[emo_i][0] +every_test[emo_i][1] + every_test[emo_i][2]\n",
    "    every_percent.append([0,0,0])\n",
    "    for bias_i in range(3):\n",
    "        every_percent[emo_i][bias_i] = (every_train[emo_i][bias_i] + every_valid[emo_i][bias_i] + every_test[emo_i][bias_i])/total_bias\n",
    "print('every_percent', every_percent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bishe",
   "language": "python",
   "name": "bishe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
